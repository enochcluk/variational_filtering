{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025e13f6-71ab-4098-9ea2-05458210b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit, jacfwd, jacrev\n",
    "from jax.scipy.linalg import inv, svd, eigh, det\n",
    "from jax.lax import scan\n",
    "from scipy.linalg import solve_discrete_are, norm\n",
    "from jax import random, jit, value_and_grad\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from jax.tree_util import Partial\n",
    "from functools import partial\n",
    "from jax_vi import KL_gaussian, log_likelihood, KL_sum, plot_optimization_results, plot_k_matrices\n",
    "from jax_filters import apply_filtering_fixed_nonlinear, kalman_filter_process, filter_step_nonlinear, ensrf_steps\n",
    "from jax_models import visualize_observations, Lorenz63, generate_true_states, generate_localization_matrix\n",
    "\n",
    "from flax.training import train_state\n",
    "from functools import partial\n",
    "import optax\n",
    "\n",
    "N = 10  # number of Monte Carlo samples\n",
    "num_steps = 1000  # Total number of time steps\n",
    "num_train_steps = 500  # Number of training time steps\n",
    "num_test_steps = num_steps - num_train_steps  # Number of testing time steps\n",
    "J0 = 0\n",
    "n = 3   # Number of state variables\n",
    "key = random.PRNGKey(42)  # Random key for reproducibility\n",
    "Q = 0.1 * jnp.eye(n)  # Process noise covariance\n",
    "R = 0.05 * jnp.eye(n)  # Observation noise covariance\n",
    "H = jnp.eye(n)  # Observation matrix (identity matrix for direct observation of all state variables)\n",
    "\n",
    "n_ensemble = 10\n",
    "observation_interval = 1\n",
    "initial_state = random.normal(random.PRNGKey(42), (n,)) \n",
    "m0 = initial_state\n",
    "C0 = Q\n",
    "\n",
    "l63_model = Lorenz63()\n",
    "l63_step = Partial(l63_model.step)\n",
    "\n",
    "jacobian_function = jacrev(l63_step, argnums=0)\n",
    "jac_func = Partial(jacobian_function)\n",
    "state_transition_function = l63_step\n",
    "\n",
    "# Generate true states and observations for 1000 steps\n",
    "true_states, observations = generate_true_states(key, num_steps, n, initial_state, H, Q, R, l63_step, observation_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff9f7df-1e09-4d7e-9ac8-9dcbc66d9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random, jit, lax\n",
    "\n",
    "@jit\n",
    "def kalman_step(state, observation, params):\n",
    "    m_prev, C_prev = state\n",
    "    state_transition_function, jacobian_function, H, Q, R = params\n",
    "    \n",
    "    # Prediction step\n",
    "    m_pred = state_transition_function(m_prev)\n",
    "    F_jac = jacobian_function(m_prev)\n",
    "    C_pred = F_jac @ C_prev @ F_jac.T + Q\n",
    "    \n",
    "    # Update step\n",
    "    S = H @ C_pred @ H.T + R\n",
    "    K_curr = C_pred @ H.T @ jnp.linalg.inv(S)\n",
    "    m_update = m_pred + K_curr @ (observation - H @ m_pred)\n",
    "    C_update = (jnp.eye(H.shape[1]) - K_curr @ H) @ C_pred\n",
    "    \n",
    "    return (m_update, C_update), (m_pred, C_pred, m_update, C_update, K_curr)\n",
    "\n",
    "@jit\n",
    "def kalman_filter_process(state_transition_function, jacobian_function, m0, C0, observations, H, Q, R):\n",
    "    params = (state_transition_function, jacobian_function, H, Q, R)\n",
    "    initial_state = (m0, C0)\n",
    "    \n",
    "    # Modified scan to capture both prediction and analysis states\n",
    "    _, (m_preds, C_preds, m_updates, C_updates, Ks) = lax.scan(\n",
    "        lambda state, obs: kalman_step(state, obs, params),\n",
    "        initial_state, \n",
    "        observations\n",
    "    )\n",
    "    \n",
    "    return m_preds, C_preds, m_updates, C_updates, Ks\n",
    "\n",
    "\n",
    "m_preds, C_preds, m_updates, C_updates, Ks = kalman_filter_process(state_transition_function, jac_func, m0, C0, observations, H, Q, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "313de9ae-b0b4-43a5-be79-dfed4844046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = random.split(key)\n",
    "ensemble_init = random.multivariate_normal(subkey, m0, C0, (n_ensemble,)).T  # Shape: (n, ensemble_size)\n",
    "localization_matrix = generate_localization_matrix(3,1)\n",
    "\n",
    "ensemble_preds, C_preds, ensembles, covariances = ensrf_steps(state_transition_function, ensemble_init, num_train_steps, observations, 1, H, Q, R, localization_matrix=localization_matrix, inflation=1.9, key=key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e080fb57-a433-4e4c-9ffd-4d017e5ecea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jit, static_argnums=(2, 5))\n",
    "def nn_analysis_filter_steps(\n",
    "    state_transition_function,\n",
    "    ensemble_init,\n",
    "    num_steps,\n",
    "    observations,\n",
    "    observation_interval,\n",
    "    model,\n",
    "    params,\n",
    "    key,\n",
    "):\n",
    "    model_vmap = jax.vmap(lambda v: state_transition_function(v), in_axes=1, out_axes=1)\n",
    "    key, *subkeys = random.split(key, num=num_steps + 1)\n",
    "    subkeys = jnp.array(subkeys)\n",
    "\n",
    "    def inner(carry, t):\n",
    "        ensemble = carry\n",
    "        ensemble_predicted = model_vmap(ensemble)\n",
    "        def true_fun(_):\n",
    "            # Flatten the predicted ensemble and prepare input for the model\n",
    "            pred_flat = ensemble_predicted.reshape(-1)  # (n_ensemble * n,)\n",
    "            input_t = jnp.concatenate([pred_flat, observations[t]])  # Append observation\n",
    "            # Use the NN to predict the analysis ensemble\n",
    "            analysis_flat = model.apply(params, input_t)\n",
    "            # Reshape back to (n, n_ensemble)\n",
    "            analysis_ensemble = analysis_flat.reshape(ensemble_predicted.shape)\n",
    "            return analysis_ensemble\n",
    "\n",
    "        def false_fun(_):\n",
    "            return ensemble_predicted\n",
    "\n",
    "        updated_ensemble = lax.cond(\n",
    "            t % observation_interval == 0, true_fun, false_fun, operand=None\n",
    "        )\n",
    "        return updated_ensemble, (ensemble_predicted, updated_ensemble)\n",
    "\n",
    "    # Perform filtering over all time steps\n",
    "    _, (ensemble_preds, ensembles) = lax.scan(\n",
    "        inner, ensemble_init, jnp.arange(num_steps)\n",
    "    )\n",
    "\n",
    "    return ensemble_preds, ensembles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64967d9b-7950-453a-a324-8c6f6989e4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88da4858998347de84db56246a55d1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: Loss: 4.11e+06\n",
      "Epoch 6, Loss: Loss: 1.83e+06\n",
      "Epoch 11, Loss: Loss: 1.20e+06\n",
      "Epoch 16, Loss: Loss: 5.10e+05\n",
      "Epoch 21, Loss: Loss: 2.07e+05\n",
      "Epoch 26, Loss: Loss: 1.58e+05\n",
      "Epoch 31, Loss: Loss: 1.21e+05\n",
      "Epoch 36, Loss: Loss: 8.24e+04\n",
      "Epoch 41, Loss: Loss: 5.95e+04\n",
      "Epoch 46, Loss: Loss: 4.84e+04\n",
      "Epoch 51, Loss: Loss: 3.65e+04\n",
      "Epoch 56, Loss: Loss: 2.52e+04\n",
      "Epoch 61, Loss: Loss: 1.80e+04\n",
      "Epoch 66, Loss: Loss: 1.20e+04\n",
      "Epoch 71, Loss: Loss: 7.36e+03\n",
      "Epoch 76, Loss: Loss: 4.95e+03\n",
      "Epoch 81, Loss: Loss: 3.55e+03\n",
      "Epoch 86, Loss: Loss: 2.62e+03\n",
      "Epoch 91, Loss: Loss: 2.06e+03\n",
      "Epoch 96, Loss: Loss: 1.64e+03\n",
      "Epoch 101, Loss: Loss: 1.36e+03\n",
      "Epoch 106, Loss: Loss: 1.17e+03\n",
      "Epoch 111, Loss: Loss: 1.02e+03\n",
      "Epoch 116, Loss: Loss: 9.14e+02\n",
      "Epoch 121, Loss: Loss: 8.35e+02\n",
      "Epoch 126, Loss: Loss: 8.41e+02\n",
      "Epoch 131, Loss: Loss: 8.05e+02\n",
      "Epoch 136, Loss: Loss: 7.49e+02\n",
      "Epoch 141, Loss: Loss: 6.33e+02\n",
      "Epoch 146, Loss: Loss: 6.55e+02\n",
      "Epoch 151, Loss: Loss: 6.34e+02\n",
      "Epoch 156, Loss: Loss: 5.52e+02\n",
      "Epoch 161, Loss: Loss: 5.27e+02\n",
      "Epoch 166, Loss: Loss: 7.55e+02\n",
      "Epoch 171, Loss: Loss: 1.04e+03\n",
      "Epoch 176, Loss: Loss: 8.57e+02\n",
      "Epoch 181, Loss: Loss: 4.81e+02\n",
      "Epoch 186, Loss: Loss: 4.23e+02\n",
      "Epoch 191, Loss: Loss: 5.07e+02\n",
      "Epoch 196, Loss: Loss: 3.86e+02\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "\n",
    "class AnalysisNet(nn.Module):\n",
    "    input_dim: int\n",
    "    output_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(512)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(512)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(self.output_dim)(x)\n",
    "        return x\n",
    "        \n",
    "key, subkey = random.split(key)\n",
    "kl_model = AnalysisNet(input_dim=inputs.shape[1], output_dim=outputs.shape[1])\n",
    "params = kl_model.init(subkey, inputs[0])\n",
    "#params = mse_state.params\n",
    "\n",
    "num_train_steps = 500\n",
    "\n",
    "@jit\n",
    "def var_cost(params):\n",
    "    key, *subkeys = random.split(random.PRNGKey(42), num=N+1)\n",
    "\n",
    "    y = observations[:num_train_steps]\n",
    "    ensemble_init = random.normal(key, (n, n_ensemble))  \n",
    "    ensemble_preds, ensembles = nn_analysis_filter_steps(\n",
    "        state_transition_function, ensemble_init, num_train_steps, y, observation_interval, kl_model, params, key\n",
    "    )\n",
    "\n",
    "    m_preds = jnp.mean(ensemble_preds, axis=2)\n",
    "\n",
    "    m_updates = jnp.mean(ensembles, axis=2)\n",
    "\n",
    "    C_preds = jnp.array([jnp.cov(ensemble.T, rowvar=False) for ensemble in ensemble_preds])\n",
    "    C_updates = jnp.array([jnp.cov(ensemble.T, rowvar=False) for ensemble in ensembles])\n",
    "    \n",
    "    kl_sum = KL_sum(m_preds, C_preds, m_updates, C_updates, n, state_transition_function, Q, key)\n",
    "\n",
    "    def inner_map(subkey):\n",
    "        return log_likelihood(random.multivariate_normal(subkey, m_updates, C_updates), y, H, R, num_train_steps, J0)\n",
    "\n",
    "    cost = kl_sum - jnp.nanmean(jax.lax.map(inner_map, jnp.vstack(subkeys)))\n",
    "    return cost\n",
    "    \n",
    "tx = optax.adam(learning_rate=1e-3)\n",
    "kl_state = train_state.TrainState.create(apply_fn=kl_model.apply, params=params, tx=tx)\n",
    "\n",
    "@jit\n",
    "def train_step(state):\n",
    "    loss, grads = value_and_grad(var_cost)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):    \n",
    "    epoch_loss = 0\n",
    "    kl_state, loss = train_step(kl_state)\n",
    "    epoch_loss = loss\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: Loss: {epoch_loss:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eb5afdf-07f5-47b3-9845-c0692b5ef244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisNet2(nn.Module):\n",
    "    input_dim: int\n",
    "    output_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, deterministic: bool = True):\n",
    "        batch_size = 1\n",
    "        pred_ensemble_flat = x[:n_ensemble * n]  \n",
    "        obs = x[n_ensemble * n:]  \n",
    "        pred_ensemble = pred_ensemble_flat.reshape(n_ensemble, n)  # Shape: (10, 3)\n",
    "\n",
    "        # Apply a 1D convolution to the ensemble part\n",
    "        pred_ensemble = nn.Conv(features=64, kernel_size=3, strides=1, padding='VALID')(pred_ensemble)\n",
    "        pred_ensemble = nn.relu(pred_ensemble)  \n",
    "\n",
    "        # Flatten the convolutional output\n",
    "        pred_ensemble_flat = pred_ensemble.reshape(-1)  # Shape: (e, 8 * 64)\n",
    "\n",
    "        # Concatenate the processed ensemble with the observations\n",
    "        combined = jnp.concatenate([pred_ensemble_flat, obs], axis=-1)  # Shape: (batch_size, 8 * 64 + 3)\n",
    "\n",
    "        # Pass through fully connected layers\n",
    "        x = nn.Dense(512)(combined)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dropout(0.3)(x, deterministic=deterministic)\n",
    "\n",
    "        # Another fully connected layer\n",
    "        x = nn.Dense(512)(x)\n",
    "        x = nn.relu(x)\n",
    "\n",
    "        # Final output layer to produce the updated analysis ensemble\n",
    "        x = nn.Dense(self.output_dim)(x)  # Shape: (batch_size, output_dim)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd74378-127f-40a1-a45c-d038a967019f",
   "metadata": {},
   "source": [
    "Loss from MSE-trained NN analysis filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7f72a88-3da4-4c57-bc96-785f002d0fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264fa3d97aa94a22b21334c3acb2fd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: Loss: 4.33e+06\n",
      "Epoch 6, Loss: Loss: 4.15e+06\n",
      "Epoch 11, Loss: Loss: 3.93e+06\n",
      "Epoch 16, Loss: Loss: 3.50e+06\n",
      "Epoch 21, Loss: Loss: 2.53e+06\n",
      "Epoch 26, Loss: Loss: 2.08e+06\n",
      "Epoch 31, Loss: Loss: 1.59e+06\n",
      "Epoch 36, Loss: Loss: 1.20e+06\n",
      "Epoch 41, Loss: Loss: 9.09e+05\n",
      "Epoch 46, Loss: Loss: 6.84e+05\n",
      "Epoch 51, Loss: Loss: 5.66e+05\n",
      "Epoch 56, Loss: Loss: 4.56e+05\n",
      "Epoch 61, Loss: Loss: 3.53e+05\n",
      "Epoch 66, Loss: Loss: 2.60e+05\n",
      "Epoch 71, Loss: Loss: 1.98e+05\n",
      "Epoch 76, Loss: Loss: 1.63e+05\n",
      "Epoch 81, Loss: Loss: 1.29e+05\n",
      "Epoch 86, Loss: Loss: 1.11e+05\n",
      "Epoch 91, Loss: Loss: 9.78e+04\n",
      "Epoch 96, Loss: Loss: 8.89e+04\n",
      "Epoch 101, Loss: Loss: 8.21e+04\n",
      "Epoch 106, Loss: Loss: 7.69e+04\n",
      "Epoch 111, Loss: Loss: 7.30e+04\n",
      "Epoch 116, Loss: Loss: 7.00e+04\n",
      "Epoch 121, Loss: Loss: 6.75e+04\n",
      "Epoch 126, Loss: Loss: 6.58e+04\n",
      "Epoch 131, Loss: Loss: 6.42e+04\n",
      "Epoch 136, Loss: Loss: 6.25e+04\n",
      "Epoch 141, Loss: Loss: 6.20e+04\n",
      "Epoch 146, Loss: Loss: 6.10e+04\n",
      "Epoch 151, Loss: Loss: 5.97e+04\n",
      "Epoch 156, Loss: Loss: 5.67e+04\n",
      "Epoch 161, Loss: Loss: 5.44e+04\n",
      "Epoch 166, Loss: Loss: 5.30e+04\n",
      "Epoch 171, Loss: Loss: 4.98e+04\n",
      "Epoch 176, Loss: Loss: 4.65e+04\n",
      "Epoch 181, Loss: Loss: 4.35e+04\n",
      "Epoch 186, Loss: Loss: 4.03e+04\n",
      "Epoch 191, Loss: Loss: 3.99e+04\n",
      "Epoch 196, Loss: Loss: 3.51e+04\n"
     ]
    }
   ],
   "source": [
    "key, subkey = random.split(key)\n",
    "kl_model2 = AnalysisNet2(input_dim=inputs.shape[1], output_dim=outputs.shape[1])\n",
    "params = kl_model2.init(subkey, inputs[0])\n",
    "#params = mse_state.params\n",
    "\n",
    "num_train_steps = 500\n",
    "\n",
    "@jit\n",
    "def var_cost(params):\n",
    "    key, *subkeys = random.split(random.PRNGKey(42), num=N+1)\n",
    "\n",
    "    y = observations[:num_train_steps]\n",
    "    ensemble_init = random.normal(key, (n, n_ensemble))  \n",
    "    ensemble_preds, ensembles = nn_analysis_filter_steps(\n",
    "        state_transition_function, ensemble_init, num_train_steps, y, observation_interval, kl_model2, params, key\n",
    "    )\n",
    "\n",
    "    m_preds = jnp.mean(ensemble_preds, axis=2)\n",
    "\n",
    "    m_updates = jnp.mean(ensembles, axis=2)\n",
    "\n",
    "    C_preds = jnp.array([jnp.cov(ensemble.T, rowvar=False) for ensemble in ensemble_preds])\n",
    "    C_updates = jnp.array([jnp.cov(ensemble.T, rowvar=False) for ensemble in ensembles])\n",
    "    \n",
    "    kl_sum = KL_sum(m_preds, C_preds, m_updates, C_updates, n, state_transition_function, Q, key)\n",
    "\n",
    "    def inner_map(subkey):\n",
    "        return log_likelihood(random.multivariate_normal(subkey, m_updates, C_updates), y, H, R, num_train_steps, J0)\n",
    "\n",
    "    cost = kl_sum - jnp.nanmean(jax.lax.map(inner_map, jnp.vstack(subkeys)))\n",
    "    return cost\n",
    "    \n",
    "tx = optax.adam(learning_rate=1e-4)\n",
    "kl_state2 = train_state.TrainState.create(apply_fn=kl_model2.apply, params=params, tx=tx)\n",
    "\n",
    "@jit\n",
    "def train_step(state):\n",
    "    loss, grads = value_and_grad(var_cost)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):    \n",
    "    epoch_loss = 0\n",
    "    kl_state2, loss = train_step(kl_state2)\n",
    "    epoch_loss = loss\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: Loss: {epoch_loss:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "02fdc4c0-03f7-4d4a-b5e5-3780b55c4129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Analysis to True State 15.012643\n",
      "RMSE Predicted to True State 15.237214\n",
      "Standard Deviation of True States (per timestep): 12.618656\n"
     ]
    }
   ],
   "source": [
    "ensemble_preds, nn_ensemble = nn_analysis_filter_steps(\n",
    "    state_transition_function=l63_step,\n",
    "    ensemble_init=ensemble_init,\n",
    "    num_steps=num_steps,\n",
    "    observations=observations,\n",
    "    observation_interval=1,\n",
    "    model=mse_model,\n",
    "    params=kl_state.params,\n",
    "    key=key,\n",
    ")\n",
    "ensemble_means = jnp.mean(nn_ensemble, axis=2)  # Shape: (num_steps, n)\n",
    "pred_means = jnp.mean(ensemble_preds, axis=2) \n",
    "# Compute the RMSE\n",
    "rmse = jnp.sqrt(jnp.mean((ensemble_means - true_states) ** 2, axis=1))  # Shape: (num_steps,)\n",
    "print(\"RMSE Analysis to True State\",jnp.mean(rmse))\n",
    "rmse = jnp.sqrt(jnp.mean((pred_means - true_states) ** 2, axis=1))  # Shape: (num_steps,)\n",
    "print(\"RMSE Predicted to True State\", jnp.mean(rmse))\n",
    "true_states_std = jnp.std(true_states, axis=1)  # Shape: (num_steps,)\n",
    "print(\"Standard Deviation of True States (per timestep):\", jnp.mean(true_states_std))\n",
    "\n",
    "\n",
    "# Compute the RMSE for extended kalman\n",
    "rmse = jnp.sqrt(jnp.mean((m_updates - true_states) ** 2, axis=1))  # Shape: (num_steps,)\n",
    "print(\"MSE Loss from Kalman Filter\", jnp.mean(rmse))\n",
    "\n",
    "key, subkey = random.split(key)\n",
    "ensemble_init = random.multivariate_normal(subkey, m0, C0, (n_ensemble,)).T  # Shape: (n, ensemble_size)\n",
    "localization_matrix = generate_localization_matrix(3,1)\n",
    "\n",
    "ensemble_preds, C_preds, ensembles, covariances = ensrf_steps(state_transition_function, ensemble_init, num_steps, observations, 1, H, Q, R, localization_matrix=localization_matrix, inflation=1.9, key=key)\n",
    "\n",
    "ensemble_means = jnp.mean(ensembles, axis=2)  # Shape: (num_steps, n)\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse = jnp.sqrt(jnp.mean((ensemble_means - true_states) ** 2, axis=1))  # Shape: (num_steps,)\n",
    "print(jnp.mean(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "094b80a4-a370-46cd-99ac-408d8528733f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPS Analysis to True State (NN) 12.7385025\n",
      "CRPS Predicted to True State (NN) 12.739106\n",
      "MSE Analysis to True State (NN) 293.74744\n",
      "MSE Predicted to True State (NN) 293.79538\n",
      "CRPS Loss from Kalman Filter 0.19136108\n",
      "MSE Loss from Kalman Filter 0.057385277\n",
      "CRPS from Ensemble Kalman Filter (EnsRF) 0.15973847\n",
      "MSE from Ensemble Kalman Filter (EnsRF) 0.058262277\n"
     ]
    }
   ],
   "source": [
    "import properscoring as ps\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "# MSE Loss Calculation\n",
    "def compute_mse_for_all_timesteps(pred_means, true_states):\n",
    "    mse_vals = jnp.mean((pred_means - true_states) ** 2, axis=1)  # Shape: (num_steps,)\n",
    "    return jnp.mean(mse_vals)\n",
    "\n",
    "# Neural Network Filter\n",
    "ensemble_preds, nn_ensemble = nn_analysis_filter_steps(\n",
    "    state_transition_function=l63_step,\n",
    "    ensemble_init=ensemble_init,\n",
    "    num_steps=num_steps,\n",
    "    observations=observations,\n",
    "    observation_interval=1,\n",
    "    model=kl_model,\n",
    "    params=kl_state.params,\n",
    "    key=key,\n",
    ")\n",
    "ensemble_means = jnp.mean(nn_ensemble, axis=2)  # Shape: (num_steps, n)\n",
    "pred_means = jnp.mean(ensemble_preds, axis=2)\n",
    "\n",
    "# Compute CRPS using properscoring for the neural network-based filtering\n",
    "crps_nn_analysis = jnp.mean(jnp.array([ps.crps_ensemble(true_states[t], nn_ensemble[t]) for t in range(nn_ensemble.shape[0])]))\n",
    "crps_nn_pred = jnp.mean(jnp.array([ps.crps_ensemble(true_states[t], ensemble_preds[t]) for t in range(ensemble_preds.shape[0])]))\n",
    "\n",
    "# Compute MSE for the neural network-based filtering\n",
    "mse_nn_analysis = compute_mse_for_all_timesteps(ensemble_means, true_states)\n",
    "mse_nn_pred = compute_mse_for_all_timesteps(pred_means, true_states)\n",
    "\n",
    "print(\"CRPS Analysis to True State (NN)\", crps_nn_analysis)\n",
    "print(\"CRPS Predicted to True State (NN)\", crps_nn_pred)\n",
    "print(\"MSE Analysis to True State (NN)\", mse_nn_analysis)\n",
    "print(\"MSE Predicted to True State (NN)\", mse_nn_pred)\n",
    "\n",
    "# Compute CRPS for extended Kalman Filter (EKF) using properscoring\n",
    "crps_ekf = jnp.mean(jnp.array([ps.crps_ensemble(true_states[t], m_updates[t]) for t in range(m_updates.shape[0])]))\n",
    "mse_ekf = compute_mse_for_all_timesteps(m_updates, true_states)\n",
    "\n",
    "print(\"CRPS Loss from Kalman Filter\", crps_ekf)\n",
    "print(\"MSE Loss from Kalman Filter\", mse_ekf)\n",
    "\n",
    "# Ensemble Kalman Filter (EnsRF)\n",
    "key, subkey = random.split(key)\n",
    "ensemble_init = random.multivariate_normal(subkey, m0, C0, (n_ensemble,)).T  # Shape: (n, ensemble_size)\n",
    "localization_matrix = generate_localization_matrix(3, 1)\n",
    "\n",
    "ensemble_preds, C_preds, ensembles, covariances = ensrf_steps(\n",
    "    state_transition_function, ensemble_init, num_steps, observations, \n",
    "    1, H, Q, R, localization_matrix=localization_matrix, inflation=1.9, key=key\n",
    ")\n",
    "\n",
    "# Compute CRPS for the ensemble-based filtering method (EnsRF) using properscoring\n",
    "crps_ensrf = jnp.mean(jnp.array([ps.crps_ensemble(true_states[t], ensembles[t]) for t in range(ensembles.shape[0])]))\n",
    "mse_ensrf = compute_mse_for_all_timesteps(jnp.mean(ensembles, axis=2), true_states)\n",
    "\n",
    "print(\"CRPS from Ensemble Kalman Filter (EnsRF)\", crps_ensrf)\n",
    "print(\"MSE from Ensemble Kalman Filter (EnsRF)\", mse_ensrf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c61b5-acbb-4351-a961-8c0794c1933f",
   "metadata": {},
   "source": [
    "Loss from Classic Kalman Filter:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb2c17-6c53-464d-acea-be75da742ae5",
   "metadata": {},
   "source": [
    "Loss from EnSRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2e426ab1-eb9e-4a48-92ad-551b72ee572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22254649\n"
     ]
    }
   ],
   "source": [
    "key, subkey = random.split(key)\n",
    "ensemble_init = random.multivariate_normal(subkey, m0, C0, (n_ensemble,)).T  # Shape: (n, ensemble_size)\n",
    "localization_matrix = generate_localization_matrix(3,1)\n",
    "\n",
    "ensemble_preds, C_preds, ensembles, covariances = ensrf_steps(state_transition_function, ensemble_init, num_steps, observations, 1, H, Q, R, localization_matrix=localization_matrix, inflation=1.9, key=key)\n",
    "\n",
    "ensemble_means = jnp.mean(ensembles, axis=2)  # Shape: (num_steps, n)\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse = jnp.sqrt(jnp.mean((ensemble_means - true_states) ** 2, axis=1))  # Shape: (num_steps,)\n",
    "print(jnp.mean(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
