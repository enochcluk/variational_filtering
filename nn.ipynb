{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "025e13f6-71ab-4098-9ea2-05458210b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit, jacfwd, jacrev\n",
    "from jax.scipy.linalg import inv, svd, eigh, det\n",
    "from jax.lax import scan\n",
    "from scipy.linalg import solve_discrete_are, norm\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from jax.tree_util import Partial\n",
    "from functools import partial\n",
    "from jax_vi import KL_gaussian, log_likelihood, KL_sum, plot_optimization_results, plot_k_matrices\n",
    "from jax_filters import apply_filtering_fixed_nonlinear, kalman_filter_process, filter_step_nonlinear, ensrf_steps\n",
    "from jax_models import visualize_observations, Lorenz63, generate_true_states, generate_localization_matrix\n",
    "\n",
    "from functools import partial\n",
    "import optax\n",
    "\n",
    "N = 10 # number of Monte Carlo samples\n",
    "num_steps = 500  # Number of time steps\n",
    "J0 = 0\n",
    "n = 3   # Number of state variables\n",
    "key = random.PRNGKey(0)  # Random key for reproducibility\n",
    "Q = 0.1 * jnp.eye(n)  # Process noise covariance\n",
    "R = 0.05 * jnp.eye(n)  # Observation noise covariance\n",
    "H = jnp.eye(n) # Observation matrix (identity matrix for direct observation of all state variables)\n",
    "\n",
    "n_ensemble = 10\n",
    "observation_interval = 1\n",
    "initial_state = random.normal(random.PRNGKey(0), (n,)) \n",
    "m0 = initial_state\n",
    "C0 = Q\n",
    "\n",
    "l63_model = Lorenz63()\n",
    "l63_step = Partial(l63_model.step)\n",
    "\n",
    "jacobian_function = jacrev(l63_step, argnums=0)\n",
    "jac_func = Partial(jacobian_function)\n",
    "state_transition_function = l63_step\n",
    "\n",
    "observations, true_states = generate_true_states(key, num_steps, n, initial_state, H, Q, R, l63_step, observation_interval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "313de9ae-b0b4-43a5-be79-dfed4844046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = random.split(key)\n",
    "ensemble_init = random.multivariate_normal(subkey, m0, C0, (n_ensemble,)).T  # Shape: (n, ensemble_size)\n",
    "localization_matrix = generate_localization_matrix(3,1)\n",
    "\n",
    "ensemble_preds, C_preds, ensembles, covariances = ensrf_steps(state_transition_function, ensemble_init, num_steps, observations, 1, H, Q, R, localization_matrix=localization_matrix, inflation=1.9, key=key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3ff9f7df-1e09-4d7e-9ac8-9dcbc66d9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random, jit, lax\n",
    "\n",
    "@jit\n",
    "def kalman_step(state, observation, params):\n",
    "    m_prev, C_prev = state\n",
    "    state_transition_function, jacobian_function, H, Q, R = params\n",
    "    \n",
    "    # Prediction step\n",
    "    m_pred = state_transition_function(m_prev)\n",
    "    F_jac = jacobian_function(m_prev)\n",
    "    C_pred = F_jac @ C_prev @ F_jac.T + Q\n",
    "    \n",
    "    # Update step\n",
    "    S = H @ C_pred @ H.T + R\n",
    "    K_curr = C_pred @ H.T @ jnp.linalg.inv(S)\n",
    "    m_update = m_pred + K_curr @ (observation - H @ m_pred)\n",
    "    C_update = (jnp.eye(H.shape[1]) - K_curr @ H) @ C_pred\n",
    "    \n",
    "    return (m_update, C_update), (m_pred, C_pred, m_update, C_update, K_curr)\n",
    "\n",
    "@jit\n",
    "def kalman_filter_process(state_transition_function, jacobian_function, m0, C0, observations, H, Q, R):\n",
    "    params = (state_transition_function, jacobian_function, H, Q, R)\n",
    "    initial_state = (m0, C0)\n",
    "    \n",
    "    # Modified scan to capture both prediction and analysis states\n",
    "    _, (m_preds, C_preds, m_updates, C_updates, Ks) = lax.scan(\n",
    "        lambda state, obs: kalman_step(state, obs, params),\n",
    "        initial_state, \n",
    "        observations\n",
    "    )\n",
    "    \n",
    "    return m_preds, C_preds, m_updates, C_updates, Ks\n",
    "\n",
    "\n",
    "m_preds, C_preds, m_updates, C_updates, Ks = kalman_filter_process(state_transition_function, jac_func, m0, C0, observations, H, Q, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "165ed6d0-c6cf-432d-8305-47f5e8c57571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e8e3197d-7c4b-49e8-af5c-cadff953c7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 33)\n",
      "(500, 30)\n"
     ]
    }
   ],
   "source": [
    "ensemble_preds = ensemble_preds.transpose(0, 2, 1)  # Shape: (num_steps, ensemble_size, n)\n",
    "ensembles = ensembles.transpose(0, 2, 1)            # Shape: (num_steps, ensemble_size, n)\n",
    "\n",
    "# Prepare inputs and outputs. Note that rather than use ensemble mean and covariances, we are using the entire ensemble\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for t in range(num_steps):\n",
    "    pred_ensemble = ensemble_preds[t]  # Shape: (ensemble_size, n)\n",
    "    obs = observations[t]              # Shape: (observation_dim,)\n",
    "    analysis_ensemble = ensembles[t]   # Shape: (ensemble_size, n)\n",
    "    \n",
    "    pred_ensemble_flat = pred_ensemble.reshape(-1)  # Shape: (ensemble_size * n,)\n",
    "    input_t = jnp.concatenate([pred_ensemble_flat, obs])  # Shape: (ensemble_size * n + observation_dim,)\n",
    "    \n",
    "    output_t = analysis_ensemble.reshape(-1)  # Flatten the analysis ensemble    \n",
    "    inputs.append(input_t)\n",
    "    outputs.append(output_t)\n",
    "\n",
    "inputs = jnp.array(inputs)   # Shape: (num_steps, input_dim)\n",
    "outputs = jnp.array(outputs) # Shape: (num_steps, output_dim)\n",
    "\n",
    "print(inputs.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce87bbaf-27a8-47bd-9cce-b996eb43c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_loss(params, batch):\n",
    "    # note that this loss does not use y at all, similar to fixed gain experiments\n",
    "    \n",
    "    x, y = batch  # x: (batch_size, input_dim), y: (batch_size, ensemble_size * n)\n",
    "    batch_size = x.shape[0]\n",
    "    ensemble_size = n_ensemble\n",
    "    n = y.shape[1] // ensemble_size  # State dimension (since y is flattened)\n",
    "    pred_ensemble_flat = x[:, :ensemble_size * n]  # Shape: (batch_size, ensemble_size * n)\n",
    "    obs = x[:, ensemble_size * n:]  # Shape: (batch_size, observation_dim)\n",
    "\n",
    "    # Reshape the predicted ensemble to (batch_size, ensemble_size, n)\n",
    "    pred_ensemble = pred_ensemble_flat.reshape(batch_size, ensemble_size, n)\n",
    "    def compute_mean_cov(ensemble):\n",
    "        mu = jnp.mean(ensemble, axis=0)  # Mean over ensemble members, shape: (n,)\n",
    "        Sigma = jnp.cov(ensemble, rowvar=False)  # Covariance, shape: (n, n)\n",
    "        return mu, Sigma\n",
    "\n",
    "    mu_pred_ensemble, Sigma_pred_ensemble = jax.vmap(compute_mean_cov)(pred_ensemble)\n",
    "    # Model prediction: predicted analysis ensemble (flattened)\n",
    "    preds = model.apply(params, x)  # preds: (batch_size, ensemble_size * n)\n",
    "    # Reshape preds and y to (batch_size, ensemble_size, n)\n",
    "    preds = preds.reshape(batch_size, ensemble_size, n)\n",
    "    y = y.reshape(batch_size, ensemble_size, n)\n",
    "    # Compute mean and covariance of the predicted analysis ensemble\n",
    "    mu_anal, Sigma_anal = jax.vmap(compute_mean_cov)(preds)\n",
    "\n",
    "    # Compute mean and covariance of the target analysis ensemble (unused)\n",
    "    # mu_y, Sigma_y = jax.vmap(compute_mean_cov)(y)\n",
    "    key = random.PRNGKey(0)  # Random key for reproducibility\n",
    "    key, *subkeys = random.split(key, num=N+1)\n",
    "    kl_sum = KL_sum(mu_pred_ensemble, Sigma_pred_ensemble, mu_anal, Sigma_anal, n, state_transition_function, Q, key)\n",
    "    def inner_map(subkey):\n",
    "        return log_likelihood(random.multivariate_normal(subkey, mu_anal, Sigma_anal), obs, H, R, J=num_steps/batch_size, J0=0)  \n",
    "    cost = kl_sum - jnp.mean(jax.lax.map(inner_map, jnp.vstack(subkeys)))\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "64967d9b-7950-453a-a324-8c6f6989e4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b36dfada7d4ecbbad68acbf9c1b03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 35939450880.0\n",
      "Epoch 2, Loss: 7468823040.0\n",
      "Epoch 3, Loss: 4116057856.0\n",
      "Epoch 4, Loss: 2309668608.0\n",
      "Epoch 5, Loss: 1059303552.0\n",
      "Epoch 6, Loss: 578861440.0\n",
      "Epoch 7, Loss: 392701216.0\n",
      "Epoch 8, Loss: 303462976.0\n",
      "Epoch 9, Loss: 177092080.0\n",
      "Epoch 10, Loss: 170842816.0\n",
      "Epoch 11, Loss: 136709280.0\n",
      "Epoch 12, Loss: 163207536.0\n",
      "Epoch 13, Loss: 140942144.0\n",
      "Epoch 14, Loss: 114853976.0\n",
      "Epoch 15, Loss: 138087680.0\n",
      "Epoch 16, Loss: 176819472.0\n",
      "Epoch 17, Loss: 180131328.0\n",
      "Epoch 18, Loss: 149741504.0\n",
      "Epoch 19, Loss: 328492224.0\n",
      "Epoch 20, Loss: 234007072.0\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "\n",
    "class AnalysisNet(nn.Module):\n",
    "    input_dim: int\n",
    "    output_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(512)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(512)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(self.output_dim)(x)\n",
    "        return x\n",
    "        \n",
    "key, subkey = random.split(key)\n",
    "model = AnalysisNet(input_dim=inputs.shape[1], output_dim=outputs.shape[1])\n",
    "params = model.init(subkey, inputs[0])\n",
    "tx = optax.adam(learning_rate=1e-3)\n",
    "kl_state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "def mse_loss(params, batch):\n",
    "    x, y = batch\n",
    "    preds = model.apply(params, x)\n",
    "    loss = jnp.mean((preds - y) ** 2)\n",
    "    return loss\n",
    "\n",
    "@jit\n",
    "def train_step(state, batch):\n",
    "    loss, grads = value_and_grad(kl_loss)(state.params, batch)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "num_batches = inputs.shape[0] // batch_size\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Shuffle the data\n",
    "    perm = random.permutation(random.PRNGKey(epoch), inputs.shape[0])\n",
    "    inputs_shuffled = inputs[perm]\n",
    "    outputs_shuffled = outputs[perm]\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for i in range(num_batches):\n",
    "        batch_indices = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        batch = (\n",
    "            inputs_shuffled[batch_indices],\n",
    "            outputs_shuffled[batch_indices],\n",
    "        )\n",
    "        kl_state, loss = train_step(kl_state, batch)\n",
    "        epoch_loss += loss\n",
    "    epoch_loss /= num_batches\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "53414328-b22e-4a08-a2e3-108b63179734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE Loss (All Timesteps): 120.82587432861328\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mse_loss(params, inputs, outputs):\n",
    "    predictions = jax.vmap(lambda x: model.apply(params, x))(inputs)\n",
    "    mse_loss = jnp.mean((predictions - outputs) ** 2)\n",
    "    return mse_loss\n",
    "final_mse_loss = evaluate_mse_loss(state.params, inputs, outputs)\n",
    "print(f\"Final MSE Loss (All Timesteps): {final_mse_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c79b3edb-b390-4f72-a94c-b2ab0cc3f902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0209048e49524449a859f96476977926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 69.54347229003906\n",
      "Epoch 2, Loss: 5.544004440307617\n",
      "Epoch 3, Loss: 1.4658074378967285\n",
      "Epoch 4, Loss: 0.45176395773887634\n",
      "Epoch 5, Loss: 0.22495898604393005\n",
      "Epoch 6, Loss: 0.16154973208904266\n",
      "Epoch 7, Loss: 0.13796788454055786\n",
      "Epoch 8, Loss: 0.12263406813144684\n",
      "Epoch 9, Loss: 0.11631610989570618\n",
      "Epoch 10, Loss: 0.11260665208101273\n",
      "Epoch 11, Loss: 0.11302581429481506\n",
      "Epoch 12, Loss: 0.10883960127830505\n",
      "Epoch 13, Loss: 0.10708191245794296\n",
      "Epoch 14, Loss: 0.10203983634710312\n",
      "Epoch 15, Loss: 0.10470855981111526\n",
      "Epoch 16, Loss: 0.0971754938364029\n",
      "Epoch 17, Loss: 0.10021547973155975\n",
      "Epoch 18, Loss: 0.0974670797586441\n",
      "Epoch 19, Loss: 0.0876523032784462\n",
      "Epoch 20, Loss: 0.09050250798463821\n"
     ]
    }
   ],
   "source": [
    "params = model.init(subkey, inputs[0])\n",
    "tx = optax.adam(learning_rate=1e-3)\n",
    "state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "def mse_loss(params, batch):\n",
    "    x, y = batch\n",
    "    preds = model.apply(params, x)\n",
    "    loss = jnp.mean((preds - y) ** 2)\n",
    "    return loss\n",
    "\n",
    "@jit\n",
    "def train_step(state, batch):\n",
    "    loss, grads = value_and_grad(mse_loss)(state.params, batch)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "num_batches = inputs.shape[0] // batch_size\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Shuffle the data\n",
    "    perm = random.permutation(random.PRNGKey(epoch), inputs.shape[0])\n",
    "    inputs_shuffled = inputs[perm]\n",
    "    outputs_shuffled = outputs[perm]\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for i in range(num_batches):\n",
    "        batch_indices = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        batch = (\n",
    "            inputs_shuffled[batch_indices],\n",
    "            outputs_shuffled[batch_indices],\n",
    "        )\n",
    "        state, loss = train_step(state, batch)\n",
    "        epoch_loss += loss\n",
    "    epoch_loss /= num_batches\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8c958758-88c8-4462-a2c2-9aeb3f76ce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE Loss (All Timesteps): 0.08142220228910446\n"
     ]
    }
   ],
   "source": [
    "final_mse_loss = evaluate_mse_loss(state.params, inputs, outputs)\n",
    "print(f\"Final MSE Loss (All Timesteps): {final_mse_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e080fb57-a433-4e4c-9ffd-4d017e5ecea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jit, static_argnums=(2, 5))\n",
    "def nn_analysis_filter_steps(\n",
    "    state_transition_function,\n",
    "    ensemble_init,\n",
    "    num_steps,\n",
    "    observations,\n",
    "    observation_interval,\n",
    "    model,\n",
    "    params,\n",
    "    key,\n",
    "):\n",
    "    \"\"\"\n",
    "    A simplified filter step function that uses a neural network for analysis.\n",
    "\n",
    "    Args:\n",
    "       \n",
    "        model: The trained neural network model.\n",
    "        params: Parameters of the trained neural network.\n",
    "        key: PRNG key for reproducibility.\n",
    "    Returns:\n",
    "        ensemble_preds: Predicted ensembles at each time step, shape (num_steps, n, n_ensemble).\n",
    "        ensembles: Analysis ensembles at each time step, shape (num_steps, n, n_ensemble).\n",
    "    \"\"\"\n",
    "    model_vmap = jax.vmap(lambda v: state_transition_function(v), in_axes=1, out_axes=1)\n",
    "    key, *subkeys = random.split(key, num=num_steps + 1)\n",
    "    subkeys = jnp.array(subkeys)\n",
    "\n",
    "    def inner(carry, t):\n",
    "        ensemble = carry\n",
    "        ensemble_predicted = model_vmap(ensemble)\n",
    "\n",
    "        def true_fun(_):\n",
    "            # Flatten the predicted ensemble and prepare input for the model\n",
    "            pred_flat = ensemble_predicted.reshape(-1)  # (n_ensemble * n,)\n",
    "            input_t = jnp.concatenate([pred_flat, observations[t]])  # Append observation\n",
    "            # Use the NN to predict the analysis ensemble\n",
    "            analysis_flat = model.apply(params, input_t)\n",
    "            # Reshape back to (n, n_ensemble)\n",
    "            analysis_ensemble = analysis_flat.reshape(ensemble_predicted.shape)\n",
    "            return analysis_ensemble\n",
    "\n",
    "        def false_fun(_):\n",
    "            return ensemble_predicted\n",
    "\n",
    "        updated_ensemble = lax.cond(\n",
    "            t % observation_interval == 0, true_fun, false_fun, operand=None\n",
    "        )\n",
    "        return updated_ensemble, (ensemble_predicted, updated_ensemble)\n",
    "\n",
    "    # Perform filtering over all time steps\n",
    "    _, (ensemble_preds, ensembles) = lax.scan(\n",
    "        inner, ensemble_init, jnp.arange(num_steps)\n",
    "    )\n",
    "\n",
    "    return ensemble_preds, ensembles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "02fdc4c0-03f7-4d4a-b5e5-3780b55c4129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.56104\n"
     ]
    }
   ],
   "source": [
    "ensemble_preds, nn_ensemble = nn_analysis_filter_steps(\n",
    "    state_transition_function=l63_step,\n",
    "    ensemble_init=ensemble_init,\n",
    "    num_steps=num_steps,\n",
    "    observations=observations,\n",
    "    observation_interval=1,\n",
    "    model=model,\n",
    "    params=state.params,\n",
    "    key=key,\n",
    ")\n",
    "ensemble_means = jnp.mean(nn_ensemble, axis=2)  # Shape: (num_steps, n)\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse = jnp.sqrt(jnp.mean((ensemble_means - true_states) ** 2, axis=1))  # Shape: (num_steps,)\n",
    "print(jnp.mean(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ed4492be-6111-4930-abb1-9bce0f979fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18123291\n"
     ]
    }
   ],
   "source": [
    "ensemble_means = m_updates\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse = jnp.sqrt(jnp.mean((ensemble_means - true_states) ** 2, axis=1))  # Shape: (num_steps,)\n",
    "print(jnp.mean(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2e426ab1-eb9e-4a48-92ad-551b72ee572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18224059\n"
     ]
    }
   ],
   "source": [
    "key, subkey = random.split(key)\n",
    "ensemble_init = random.multivariate_normal(subkey, m0, C0, (n_ensemble,)).T  # Shape: (n, ensemble_size)\n",
    "localization_matrix = generate_localization_matrix(3,1)\n",
    "\n",
    "ensemble_preds, C_preds, ensembles, covariances = ensrf_steps(state_transition_function, ensemble_init, num_steps, observations, 1, H, Q, R, localization_matrix=localization_matrix, inflation=1.9, key=key)\n",
    "\n",
    "ensemble_means = jnp.mean(ensembles, axis=2)  # Shape: (num_steps, n)\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse = jnp.sqrt(jnp.mean((ensemble_means - true_states) ** 2, axis=1))  # Shape: (num_steps,)\n",
    "print(jnp.mean(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
